"""
Arena Leaderboard Scraper using Playwright
ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–æŠ“å– lmarena.ai æ•°æ® (å’Œ Antigravity çš„ browser_subagent åŽŸç†ä¸€æ ·)

è¡¨æ ¼åˆ—ç»“æž„ï¼ˆ2026å¹´2æœˆç¡®è®¤ï¼‰:
- td:nth-child(1) = Rank
- td:nth-child(2) = Rank Spread
- td:nth-child(3) = Model (å«é“¾æŽ¥)
- td:nth-child(4) = Score (Elo)
- td:nth-child(5) = 95% CI
- td:nth-child(6) = Votes
- td:nth-child(7) = Organization
"""
import json
from datetime import datetime
from typing import Dict, List, Any
from playwright.sync_api import sync_playwright


class ArenaLeaderboardScraper:
    """ä½¿ç”¨ Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–æŠ“å– Arena æŽ’è¡Œæ¦œ"""
    
    LEADERBOARD_URL = "https://lmarena.ai/leaderboard/text"
    
    def __init__(self, headless: bool = True):
        self.headless = headless
    
    def fetch_leaderboard(self) -> Dict[str, Any]:
        """æŠ“å–æŽ’è¡Œæ¦œæ•°æ®"""
        result = {
            "timestamp": datetime.now().isoformat(),
            "source": "lmarena.ai",
            "category": "text",
            "last_updated": None,
            "total_votes": None,
            "total_models": None,
            "models": [],
            "error": None
        }
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=self.headless)
            page = browser.new_page()
            
            try:
                print("ðŸŒ æ‰“å¼€ lmarena.ai/leaderboard/text ...")
                page.goto(self.LEADERBOARD_URL, timeout=30000)
                
                print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
                page.wait_for_load_state("networkidle", timeout=20000)
                page.wait_for_selector("table tbody tr", timeout=15000)
                
                print("ðŸ“Š æå–è¡¨æ ¼æ•°æ®...")
                models = self._extract_table_data(page)
                result["models"] = models
                result["total_count"] = len(models)
                
                # å°è¯•æå–é¡µé¢å…ƒæ•°æ®ï¼ˆLast Updated, Total Votesï¼‰
                try:
                    meta = page.evaluate('''
                        () => {
                            const text = document.body.innerText;
                            const lastUpdated = text.match(/Last Updated\\s*([A-Za-z]+\\s+\\d+,?\\s*\\d*)/)?.[1];
                            const totalVotes = text.match(/Total Votes\\s*([\\d,]+)/)?.[1];
                            const totalModels = text.match(/Total Models\\s*(\\d+)/)?.[1];
                            return { lastUpdated, totalVotes, totalModels };
                        }
                    ''')
                    result["last_updated"] = meta.get("lastUpdated")
                    result["total_votes"] = meta.get("totalVotes")
                    result["total_models"] = meta.get("totalModels")
                except:
                    pass
                
            except Exception as e:
                result["error"] = str(e)
                print(f"âŒ é”™è¯¯: {e}")
            finally:
                browser.close()
        
        return result
    
    def _extract_table_data(self, page) -> List[Dict[str, Any]]:
        """ä»Žé¡µé¢è¡¨æ ¼æå–æ•°æ® - ä½¿ç”¨æ­£ç¡®çš„é€‰æ‹©å™¨"""
        
        table_data = page.evaluate('''
            () => {
                const rows = Array.from(document.querySelectorAll('table tbody tr'));
                return rows.map(row => {
                    const cells = row.querySelectorAll('td');
                    if (cells.length < 7) return null;
                    
                    // æ­£ç¡®çš„åˆ—æ˜ å°„
                    const rankText = cells[0]?.innerText?.trim() || '';
                    const modelCell = cells[2];  // Model åˆ—
                    const scoreText = cells[3]?.innerText?.trim() || '';
                    const votesText = cells[5]?.innerText?.trim() || '';
                    const orgText = cells[6]?.innerText?.trim() || '';
                    
                    // æå–æ¨¡åž‹åï¼ˆä»Žé“¾æŽ¥æˆ–æ–‡æœ¬ï¼‰
                    const modelLink = modelCell?.querySelector('a');
                    const modelName = modelLink?.innerText?.trim() || modelCell?.innerText?.trim() || '';
                    
                    // è§£æžæ•°å€¼
                    const rank = parseInt(rankText) || null;
                    const score = parseInt(scoreText.replace(/,/g, '')) || null;
                    const votes = votesText.replace(/,/g, '');
                    
                    return {
                        rank: rank,
                        model_name: modelName,
                        elo_score: score,
                        votes: votes,
                        organization: orgText
                    };
                }).filter(x => x && x.model_name);
            }
        ''')
        
        return table_data or []
    
    def get_top_models(self, n: int = 20) -> List[Dict[str, Any]]:
        """èŽ·å–å‰ N åæ¨¡åž‹"""
        data = self.fetch_leaderboard()
        return data.get("models", [])[:n]
    
    def get_company_rankings(self) -> Dict[str, Dict[str, Any]]:
        """èŽ·å–å„å…¬å¸æœ€ä½³æ¨¡åž‹æŽ’å"""
        data = self.fetch_leaderboard()
        company_best = {}
        
        company_keywords = {
            "OpenAI": ["openai", "gpt", "chatgpt", "o1", "o3"],
            "Anthropic": ["anthropic", "claude"],
            "Google": ["google", "gemini"],
            "xAI": ["xai", "grok"],
            "DeepSeek": ["deepseek"],
            "Meta": ["meta", "llama"],
            "Mistral": ["mistral"],
            "Alibaba": ["alibaba", "qwen", "é€šä¹‰"],
            "ByteDance": ["bytedance", "doubao", "è±†åŒ…", "seed"],
            "Baidu": ["baidu", "ernie", "æ–‡å¿ƒ"],
            "Zhipu AI": ["zhipu", "glm", "æ™ºè°±"],
            "MiniMax": ["minimax"],
            "Moonshot": ["moonshot", "kimi"],
            "Cohere": ["cohere", "command"],
            "AI21 Labs": ["ai21", "jamba"],
        }
        
        for model in data.get("models", []):
            name_lower = model.get("model_name", "").lower()
            org_lower = model.get("organization", "").lower()
            
            for company, keywords in company_keywords.items():
                if any(kw in name_lower or kw in org_lower for kw in keywords):
                    if company not in company_best:
                        company_best[company] = {
                            "best_model": model.get("model_name"),
                            "best_rank": model.get("rank"),
                            "best_elo": model.get("elo_score"),
                            "all_models": []
                        }
                    company_best[company]["all_models"].append(model)
                    break
        
        return company_best


def main():
    """æµ‹è¯•æŠ“å–"""
    scraper = ArenaLeaderboardScraper(headless=True)
    
    print("=" * 75)
    print("ðŸ” LMArena æŽ’è¡Œæ¦œæŠ“å–å™¨ (Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–)")
    print("=" * 75)
    
    data = scraper.fetch_leaderboard()
    
    if data.get("error"):
        print(f"âŒ é”™è¯¯: {data['error']}")
        return
    
    print(f"\nâœ… æˆåŠŸæŠ“å– {data.get('total_count', 0)} ä¸ªæ¨¡åž‹")
    print(f"â° æŠ“å–æ—¶é—´: {data['timestamp']}")
    if data.get("last_updated"):
        print(f"ðŸ“… æ¦œå•æ›´æ–°: {data['last_updated']}")
    if data.get("total_votes"):
        print(f"ðŸ—³ï¸  æ€»æŠ•ç¥¨æ•°: {data['total_votes']}")
    
    print("\nðŸ“Š Top 15:")
    print("-" * 75)
    print(f"{'Rank':>4} | {'Model':<40} | {'Elo':>5} | {'Organization':<12}")
    print("-" * 75)
    
    for model in data.get("models", [])[:15]:
        name = model.get('model_name', '')[:40]
        elo = model.get('elo_score') or 'N/A'
        rank = model.get('rank') or 'N/A'
        org = model.get('organization', '')[:12]
        print(f"{rank:>4} | {name:<40} | {elo:>5} | {org:<12}")
    
    # ä¿å­˜å®Œæ•´æ•°æ®
    with open("arena_data.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"\nðŸ’¾ å®Œæ•´æ•°æ®å·²ä¿å­˜è‡³ arena_data.json")
    
    # å…¬å¸æŽ’å
    print("\nðŸ“ˆ å„å…¬å¸æœ€ä½³æŽ’å:")
    print("-" * 75)
    
    # é‡æ–°èŽ·å–æ•°æ®ï¼ˆä½¿ç”¨å·²æœ‰æ•°æ®ï¼Œä¸é‡å¤è¯·æ±‚ï¼‰
    company_keywords = {
        "OpenAI": ["openai", "gpt", "chatgpt", "o1", "o3"],
        "Anthropic": ["anthropic", "claude"],
        "Google": ["google", "gemini"],
        "xAI": ["xai", "grok"],
        "DeepSeek": ["deepseek"],
        "Meta": ["meta", "llama"],
        "Mistral": ["mistral"],
        "Alibaba / Qwen": ["alibaba", "qwen"],
        "Baidu": ["baidu", "ernie"],
        "Zhipu AI": ["zhipu", "glm"],
        "MiniMax": ["minimax"],
        "Moonshot": ["moonshot", "kimi"],
    }
    
    company_best = {}
    for model in data.get("models", []):
        name_lower = model.get("model_name", "").lower()
        org_lower = model.get("organization", "").lower()
        
        for company, keywords in company_keywords.items():
            if any(kw in name_lower or kw in org_lower for kw in keywords):
                if company not in company_best:
                    company_best[company] = model
                break
    
    for company, model in sorted(company_best.items(), key=lambda x: x[1].get("rank", 999)):
        print(f"{company:18s} | #{model['rank']:3d} | {model['model_name'][:35]:<35} | Elo: {model['elo_score']}")


if __name__ == "__main__":
    main()
