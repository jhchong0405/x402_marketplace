"""
AI å…¬å¸æ’åé¢„æµ‹å¼•æ“ - ç²¾ç®€ç‰ˆ

æ•°æ®æ¥æº:
1. Arena Scraper â†’ ç²¾ç¡® Elo åˆ†æ•°
2. LLM Search â†’ æ–°æ¨¡å‹é¢„æœŸ + å‘å¸ƒæ—¶é—´çº¿

è¾“å‡º:
- ç°åœ¨: å½“å‰æœ€ä½³å…¬å¸
- 1ä¸ªæœˆå: é¢„æµ‹æœ€ä½³
- 3ä¸ªæœˆå: é¢„æµ‹æœ€ä½³  
- 6ä¸ªæœˆå: é¢„æµ‹æœ€ä½³
"""
import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import json
from datetime import datetime
from typing import Dict, List, Any, Optional

from arena_scraper import ArenaLeaderboardScraper
from api_wrapper import ModelAPIWrapper


class PredictionEngine:
    """AI å…¬å¸æ’åé¢„æµ‹å¼•æ“"""
    
    # å…³æ³¨çš„å…¬å¸åˆ—è¡¨
    DEFAULT_COMPANIES = [
        "OpenAI", "Google", "Anthropic", "xAI", 
        "DeepSeek", "Baidu", "Zhipu AI", "Moonshot",
        "Meta", "Mistral", "MiniMax", "Alibaba"
    ]
    
    def __init__(self, companies: Optional[List[str]] = None):
        self.companies = companies or self.DEFAULT_COMPANIES
        self.api = ModelAPIWrapper()
        self.arena_scraper = ArenaLeaderboardScraper(headless=True)
    
    def run(self) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´é¢„æµ‹æµç¨‹"""
        print("ğŸš€ å¯åŠ¨ AI æ’åé¢„æµ‹å¼•æ“")
        print(f"ğŸ“Š åˆ†æå…¬å¸: {', '.join(self.companies)}")
        print("=" * 60)
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "companies": self.companies,
            "arena_data": {},
            "search_data": {},
            "predictions": {}
        }
        
        # Step 1: è·å– Arena ç²¾ç¡®æ’å
        print("\nğŸ“Š Step 1: æŠ“å– Arena æ’è¡Œæ¦œ...")
        arena_rankings = self._fetch_arena_rankings()
        result["arena_data"] = arena_rankings
        
        # Step 2: LLM æœç´¢æ–°æ¨¡å‹é¢„æœŸ + å‘å¸ƒæ—¶é—´çº¿
        print("\nğŸ” Step 2: æœç´¢æ–°æ¨¡å‹é¢„æœŸä¸å‘å¸ƒæ—¶é—´çº¿...")
        search_data = self._search_model_predictions(arena_rankings)
        result["search_data"] = search_data
        
        # Step 3: ç»¼åˆé¢„æµ‹
        print("\nğŸ”® Step 3: ç”Ÿæˆé¢„æµ‹...")
        predictions = self._generate_predictions(arena_rankings, search_data)
        result["predictions"] = predictions
        
        return result
    
    def _fetch_arena_rankings(self) -> Dict[str, Any]:
        """è·å– Arena æ’åæ•°æ®"""
        try:
            data = self.arena_scraper.fetch_leaderboard()
            
            # æŒ‰å…¬å¸ç­›é€‰
            company_rankings = {}
            for company in self.companies:
                company_lower = company.lower()
                best_model = None
                
                for model in data.get("models", []):
                    name = model.get("model_name", "").lower()
                    org = model.get("organization", "").lower()
                    
                    # åŒ¹é…å…¬å¸
                    if self._match_company(company_lower, name, org):
                        if best_model is None or model.get("rank", 999) < best_model.get("rank", 999):
                            best_model = model
                
                if best_model:
                    company_rankings[company] = {
                        "rank": best_model["rank"],
                        "elo": best_model["elo_score"],
                        "model": best_model["model_name"],
                        "organization": best_model.get("organization", "")
                    }
                else:
                    company_rankings[company] = {"rank": None, "elo": None, "model": None}
            
            # æŒ‰æ’åæ’åºæ‰¾å‡ºå½“å‰é¢†å…ˆè€…
            ranked = sorted(
                [(c, d) for c, d in company_rankings.items() if d.get("rank")],
                key=lambda x: x[1]["rank"]
            )
            
            return {
                "last_updated": data.get("last_updated"),
                "total_models": data.get("total_count"),
                "company_rankings": company_rankings,
                "current_leader": ranked[0][0] if ranked else None,
                "current_top5": [c for c, _ in ranked[:5]]
            }
            
        except Exception as e:
            print(f"âŒ Arena æŠ“å–å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _match_company(self, company: str, model_name: str, org: str) -> bool:
        """åŒ¹é…å…¬å¸å"""
        keywords_map = {
            "openai": ["openai", "gpt", "chatgpt", "o1", "o3"],
            "google": ["google", "gemini"],
            "anthropic": ["anthropic", "claude"],
            "xai": ["xai", "grok"],
            "deepseek": ["deepseek"],
            "meta": ["meta", "llama"],
            "mistral": ["mistral"],
            "alibaba": ["alibaba", "qwen"],
            "baidu": ["baidu", "ernie"],
            "zhipu": ["zhipu", "glm", "æ™ºè°±"],
            "minimax": ["minimax"],
            "moonshot": ["moonshot", "kimi"],
        }
        
        company_clean = company.lower().replace(" ", "").replace("ai", "")
        keywords = keywords_map.get(company_clean, [company.lower()])
        
        return any(kw in model_name or kw in org for kw in keywords)
    
    def _search_model_predictions(self, arena_data: Dict) -> Dict[str, Any]:
        """LLM æœç´¢ï¼šæ–°æ¨¡å‹é¢„æœŸ + å‘å¸ƒæ—¶é—´çº¿"""
        
        # æ„å»ºå½“å‰çŠ¶æ€æ‘˜è¦
        rankings_summary = []
        for company, data in arena_data.get("company_rankings", {}).items():
            if data.get("rank"):
                rankings_summary.append(f"{company}: #{data['rank']} ({data['model']}, Elo {data['elo']})")
        
        prompt = f"""
è¯·ä½¿ç”¨è”ç½‘æœç´¢ï¼Œåˆ†æä»¥ä¸‹ AI å…¬å¸çš„æ¨¡å‹å‘å¸ƒè®¡åˆ’å’Œé¢„æœŸã€‚

ã€å½“å‰ Arena æ’åã€‘(æ¥è‡ª lmarena.ai, {arena_data.get('last_updated', 'æœ€æ–°')})
{chr(10).join(rankings_summary)}

ã€éœ€è¦æœç´¢çš„ä¿¡æ¯ã€‘
å¯¹äºæ¯å®¶å…¬å¸ï¼Œè¯·æœç´¢ï¼ˆ**é‡ç‚¹å…³æ³¨æ–‡æœ¬/ä»£ç ç”Ÿæˆå¤§æ¨¡å‹**ï¼Œå¿½ç•¥çº¯å›¾åƒ/è§†é¢‘æ¨¡å‹ï¼‰ï¼š
1. **å³å°†å‘å¸ƒçš„æ–°ä¸€ä»£æ–‡æœ¬æ¨¡å‹**ï¼šæ˜¯å¦æœ‰å®˜æ–¹é¢„å‘Šæˆ–æ³„éœ²ä¿¡æ¯ï¼Ÿï¼ˆå¦‚ GPT-5, Gemini 2, Claude 4 ç­‰ï¼‰
2. **é¢„æœŸæ–‡æœ¬èƒ½åŠ›**ï¼šåŸºäºæŠ€æœ¯åšå®¢ã€è®ºæ–‡ã€ç¤¾åŒºåé¦ˆï¼Œæ–°æ¨¡å‹çš„æ¨ç†/ç¼–ç¨‹/å†™ä½œèƒ½åŠ›é¢„æœŸå¦‚ä½•ï¼Ÿ
3. **å‘å¸ƒå‘¨æœŸ**ï¼šè¯¥å…¬å¸çš„æ–‡æœ¬æ¨¡å‹å†å²å‘å¸ƒé—´éš”æ˜¯å¤šå°‘ï¼Ÿè·ä¸Šæ¬¡å‘å¸ƒå¤šä¹…äº†ï¼Ÿ

ã€è¾“å‡º JSONã€‘
```json
{{
  "companies": [
    {{
      "name": "å…¬å¸å",
      "upcoming_model": {{
        "name": "æ¨¡å‹åæˆ–null",
        "expected_release": "2026-Q1 / 2026-03 / æœªçŸ¥",
        "expected_arena_rank": "é¢„è®¡æ’å1-5/5-10/10+/æœªçŸ¥",
        "confidence": "é«˜/ä¸­/ä½",
        "evidence": "ä¾æ®è¯´æ˜"
      }},
      "release_interval_months": 6,
      "months_since_last_release": 3,
      "momentum": "ä¸Šå‡/ç¨³å®š/ä¸‹é™"
    }}
  ],
  "key_signals": ["é‡è¦ä¿¡å·1", "é‡è¦ä¿¡å·2"],
  "search_date": "2026-02-09"
}}
```
"""
        try:
            return self.api.call_json(prompt, api_type="qwen")
        except Exception as e:
            print(f"âŒ LLM æœç´¢å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _generate_predictions(self, arena_data: Dict, search_data: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆé¢„æµ‹"""
        
        prompt = f"""
åŸºäºä»¥ä¸‹æ•°æ®ï¼Œé¢„æµ‹ AI å…¬å¸æ’åçš„æœªæ¥å˜åŒ–ã€‚

ã€å½“å‰ Arena æ’åã€‘
å½“å‰é¢†å…ˆ: {arena_data.get('current_leader')}
Top 5: {', '.join(arena_data.get('current_top5', []))}

å…¬å¸è¯¦æƒ…:
{json.dumps(arena_data.get('company_rankings', {}), ensure_ascii=False, indent=2)}

ã€æ–°æ¨¡å‹é¢„æœŸä¸å‘å¸ƒæ—¶é—´çº¿ã€‘
{json.dumps(search_data, ensure_ascii=False, indent=2)}

ã€é¢„æµ‹è§„åˆ™ã€‘
1. **èšç„¦æ–‡æœ¬/å¯¹è¯èƒ½åŠ›**ï¼šä»…è€ƒè™‘ LLM (Text/Chat) æ¨¡å‹çš„ç«äº‰åŠ›ã€‚
2. å¦‚æœæŸå…¬å¸æœ‰å³å°†å‘å¸ƒçš„å¼ºåŠ›æ–‡æœ¬æ¨¡å‹(é¢„æœŸæ’å1-5)ï¼Œåº”åœ¨é¢„æµ‹ä¸­æƒé‡è¾ƒé«˜ã€‚
3. å‘å¸ƒå‘¨æœŸåˆ†æï¼šè·ä¸Šæ¬¡å‘å¸ƒå·²è¶…è¿‡å¹³å‡é—´éš”çš„å…¬å¸ï¼Œå¯èƒ½å³å°†å‘æ–°æ¨¡å‹ã€‚
4. å½“å‰é¢†å…ˆè€…è‹¥æ— æ–°æ¨¡å‹è®¡åˆ’ï¼Œé•¿æœŸå¯èƒ½è¢«è¶…è¶Šã€‚

ã€è¾“å‡º JSONã€‘
```json
{{
  "now": {{
    "leader": "å½“å‰é¢†å…ˆå…¬å¸",
    "model": "å½“å‰æœ€å¼ºæ¨¡å‹",
    "elo": 1500,
    "reason": "åŸå› "
  }},
  "1_month": {{
    "leader": "é¢„æµ‹é¢†å…ˆå…¬å¸",
    "likely_model": "å¯èƒ½çš„æ¨¡å‹",
    "confidence": 0.8,
    "key_change": "å…³é”®å˜åŒ–è¯´æ˜"
  }},
  "3_months": {{
    "leader": "é¢„æµ‹é¢†å…ˆå…¬å¸",
    "likely_model": "å¯èƒ½çš„æ¨¡å‹",
    "confidence": 0.6,
    "key_change": "å…³é”®å˜åŒ–è¯´æ˜"
  }},
  "6_months": {{
    "leader": "é¢„æµ‹é¢†å…ˆå…¬å¸",
    "likely_model": "å¯èƒ½çš„æ¨¡å‹", 
    "confidence": 0.5,
    "key_change": "å…³é”®å˜åŒ–è¯´æ˜"
  }},
  "ranking_trend": [
    {{"company": "å…¬å¸å", "direction": "ä¸Šå‡/ä¸‹é™/ç¨³å®š", "reason": "åŸå› "}}
  ],
  "prediction_summary": "æ€»ä½“é¢„æµ‹æ‘˜è¦"
}}
```
"""
        try:
            return self.api.call_json(prompt, api_type="qwen")
        except Exception as e:
            print(f"âŒ é¢„æµ‹ç”Ÿæˆå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def print_results(self, result: Dict[str, Any]):
        """æ‰“å°é¢„æµ‹ç»“æœ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š é¢„æµ‹ç»“æœ")
        print("=" * 60)
        
        pred = result.get("predictions", {})
        
        # å½“å‰
        now = pred.get("now", {})
        print(f"\nğŸ† ç°åœ¨: {now.get('leader', 'N/A')}")
        print(f"   æ¨¡å‹: {now.get('model', 'N/A')} (Elo: {now.get('elo', 'N/A')})")
        
        # æœªæ¥é¢„æµ‹
        for period in ["1_month", "3_months", "6_months"]:
            p = pred.get(period, {})
            label = period.replace("_", " ")
            print(f"\nğŸ”® {label}: {p.get('leader', 'N/A')} (ç½®ä¿¡åº¦: {p.get('confidence', 'N/A')})")
            if p.get("key_change"):
                print(f"   å…³é”®å˜åŒ–: {p.get('key_change')}")
        
        # è¶‹åŠ¿
        if pred.get("ranking_trend"):
            print("\nğŸ“ˆ è¶‹åŠ¿é¢„æµ‹:")
            for t in pred.get("ranking_trend", [])[:5]:
                print(f"   {t.get('company')}: {t.get('direction')} - {t.get('reason', '')[:50]}")
