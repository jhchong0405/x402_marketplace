import json
import sys
import os
from datetime import datetime, timezone, timedelta
from typing import Any, Dict, List

# è®© Windsurf ç›´æ¥è¿è¡Œæ—¶ä¹Ÿèƒ½æ‰¾åˆ°å…¶ä»–æ¨¡å—
if __name__ == "__main__" and __package__ is None:
    _pkg_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if _pkg_root not in sys.path:
        sys.path.insert(0, _pkg_root)
    from gold_analyzer.factor_collector import collect_factors
    from gold_analyzer.deep_analyzer import deep_analyze
    from gold_analyzer.price_fetcher import fetch_gold_prices, format_price_context, get_price_summary
    from gold_analyzer.reporting import build_report, save_report_json
    from gold_analyzer.scoring import compute_score, get_level_weight_mapping_from_ai
    from gold_analyzer.factor_data import ai_select_proxies, fetch_proxy_data, build_feature_matrix
    from gold_analyzer.regression import train_and_predict, compute_combined_probability
    from gold_analyzer.news_fetcher import fetch_all_gold_news, format_news_context
else:
    from .factor_collector import collect_factors
    from .deep_analyzer import deep_analyze
    from .price_fetcher import fetch_gold_prices, format_price_context, get_price_summary
    from .reporting import build_report, save_report_json
    from .scoring import compute_score, get_level_weight_mapping_from_ai
    from .factor_data import ai_select_proxies, fetch_proxy_data, build_feature_matrix
    from .regression import train_and_predict, compute_combined_probability
    from .news_fetcher import fetch_all_gold_news, format_news_context


def _normalize_factor(f: Any) -> Dict[str, Any]:
    """å…¼å®¹ä¸åŒ AI è¿”å›çš„å­—æ®µåï¼Œç»Ÿä¸€æˆæ ‡å‡†æ ¼å¼"""
    if not isinstance(f, dict):
        return {"name": str(f), "direction": "unknown", "impact_level": "medium",
                "weight": 5, "impact_score": 5, "reasoning": "", "category": "", "description": "",
                "source_type": "unknown", "source_ref": ""}
    # å…¼å®¹ Qwen å¯èƒ½ç”¨çš„å„ç§å­—æ®µåï¼ˆåŒ…æ‹¬æ‹¼å†™é”™è¯¯å¦‚ direcctionï¼‰
    name = f.get("name") or f.get("factor") or f.get("factor_name") or f.get("å› ç´ ") or ""
    direction = (f.get("direction") or f.get("direcction") or f.get("impact_direction")
                 or f.get("effect") or f.get("æ–¹å‘") or "")
    impact_level = (f.get("impact_level") or f.get("influence") or f.get("level")
                    or f.get("importance") or f.get("å½±å“ç¨‹åº¦") or "")
    weight = f.get("weight") or f.get("value") or f.get("importance_weight") or f.get("æƒé‡") or 5
    impact_score = f.get("impact_score") or f.get("score") or f.get("value") or f.get("å½±å“åˆ†æ•°") or 5
    reasoning = (f.get("reasoning") or f.get("reason") or f.get("explanation")
                 or f.get("analysis") or f.get("åŸå› ") or "")
    category = f.get("category") or f.get("type") or f.get("åˆ†ç±»") or ""
    description = f.get("description") or f.get("detail") or f.get("details") or f.get("æè¿°") or ""
    source_type = f.get("source_type") or f.get("æ¥æºç±»å‹") or "unknown"
    source_ref = f.get("source_ref") or f.get("æ¥æºå¼•ç”¨") or ""
    return {
        "name": name if name else "æœªçŸ¥å› ç´ ",
        "direction": str(direction).strip().lower() if direction else "unknown",
        "impact_level": str(impact_level).strip().lower() if impact_level else "medium",
        "weight": weight, "impact_score": impact_score,
        "reasoning": reasoning, "category": category, "description": description,
        "source_type": str(source_type).strip().lower(),
        "source_ref": str(source_ref).strip(),
    }


def _extract_factors(factors_result: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä» AI è¿”å›çš„ç»“æœä¸­æå–å› ç´ åˆ—è¡¨ï¼Œå…¼å®¹å¤šç§ç»“æ„"""
    raw = factors_result.get("factors") or factors_result.get("key_factors") or factors_result.get("data") or []
    if not isinstance(raw, list):
        raw = []

    # è¿‡æ»¤æ‰ç©ºå­—å…¸
    raw = [f for f in raw if isinstance(f, dict) and len(f) > 0]

    # å¦‚æœ factors æ•°ç»„ä¸ºç©ºï¼Œä½†é¡¶å±‚æœ‰ name å­—æ®µï¼Œè¯´æ˜ Qwen æŠŠå› ç´ æ”¾åœ¨äº†é¡¶å±‚
    if len(raw) == 0 and factors_result.get("name"):
        # æŠŠé¡¶å±‚å½“ä½œä¸€ä¸ªå› ç´ 
        top_factor = {k: v for k, v in factors_result.items()
                      if k not in ("analysis_date", "factors", "total_factors_count",
                                   "key_factors", "data")}
        raw = [top_factor]

    return [_normalize_factor(f) for f in raw]


def print_analysis(current_time: str, target_date: str, price_summary: dict,
                   factors: List[Dict[str, Any]], deep_result: dict, score_result: dict,
                   regression_result: dict = None, combined_result: dict = None,
                   proxy_mapping: dict = None) -> None:
    """æ‰“å°å®Œæ•´çš„åˆ†ææŠ¥å‘Šåˆ°å±å¹•"""
    print("\n" + "=" * 80)
    print("  AI é»„é‡‘ä»·æ ¼åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print(f"åˆ†ææ—¶é—´: {current_time}")
    print(f"é¢„æµ‹ç›®æ ‡æ—¥æœŸ: {target_date}")

    # ä»·æ ¼æ‘˜è¦
    if "error" not in price_summary:
        print(f"\næœ€æ–°æ”¶ç›˜ä»·: ${price_summary.get('latest_close')}  ({price_summary.get('latest_date')})")
        if price_summary.get('ma_20'):
            print(f"å‡çº¿: MA20=${price_summary['ma_20']}  MA50=${price_summary.get('ma_50')}  MA200=${price_summary.get('ma_200')}")
        changes = []
        if price_summary.get('pct_change_1w') is not None:
            changes.append(f"1å‘¨:{price_summary['pct_change_1w']:+.2f}%")
        if price_summary.get('pct_change_1m') is not None:
            changes.append(f"1æœˆ:{price_summary['pct_change_1m']:+.2f}%")
        if price_summary.get('pct_change_3m') is not None:
            changes.append(f"3æœˆ:{price_summary['pct_change_3m']:+.2f}%")
        if changes:
            print(f"æ¶¨è·Œå¹…: {' | '.join(changes)}")

    # å…³é”®å› ç´ 
    print("\n" + "-" * 80)
    print("  å…³é”®å½±å“å› ç´ ï¼ˆAI å®šæ€§åˆ†æï¼‰")
    print("-" * 80)
    for i, f in enumerate(factors, 1):
        direction_cn = "çœ‹æ¶¨ â†‘" if f['direction'] == 'positive' else "çœ‹è·Œ â†“" if f['direction'] == 'negative' else "æœªçŸ¥"
        level_cn = {"high": "é«˜", "medium": "ä¸­", "low": "ä½"}.get(f['impact_level'], f['impact_level'])
        # æ¥æºæ ‡ç­¾
        src_type = f.get('source_type', 'unknown')
        src_labels = {"news": "ğŸ“°æ–°é—»", "price_data": "ğŸ“Šä»·æ ¼æ•°æ®", "general_knowledge": "ğŸ“šå¸¸è¯†"}
        src_label = src_labels.get(src_type, f"â“{src_type}")
        src_ref = f.get('source_ref', '')

        print(f"\n  [{i}] {f['name']}")
        print(f"      æ–¹å‘: {direction_cn}  |  å½±å“ç¨‹åº¦: {level_cn}  |  æƒé‡: {f['weight']}")
        print(f"      æ¥æº: {src_label}  {src_ref}")
        if f.get('category'):
            print(f"      åˆ†ç±»: {f['category']}")
        if f.get('description'):
            print(f"      ç°çŠ¶: {f['description']}")
        if f.get('reasoning'):
            print(f"      åŸå› : {f['reasoning']}")

    # å› ç´ é‡åŒ–æ˜ å°„
    if proxy_mapping:
        selected = proxy_mapping.get("selected_proxies", [])
        if selected:
            print("\n" + "-" * 80)
            print("  å› ç´  â†’ é‡åŒ–ä»£ç†æŒ‡æ ‡æ˜ å°„")
            print("-" * 80)
            for sp in selected:
                dir_cn = "â†‘åˆ©å¤š" if sp.get("direction_on_gold") == "positive" else "â†“åˆ©ç©º"
                print(f"  {sp.get('mapped_factor', '')} â†’ {sp.get('proxy_id', '')} (æƒé‡:{sp.get('ai_weight', '')}, {dir_cn})")

    # ========== æ ¸å¿ƒè¾“å‡ºï¼šæ¶¨è·Œæ¦‚ç‡ ==========
    if combined_result and "error" not in combined_result:
        print("\n" + "=" * 80)
        print("  â˜… æœ€ç»ˆé¢„æµ‹ç»“æœ â˜…")
        print("=" * 80)
        prob_up = combined_result.get("final_probability_up", 0.5)
        prob_down = combined_result.get("final_probability_down", 0.5)
        prediction = combined_result.get("final_prediction", "")

        # å¤§å·æ˜¾ç¤º
        bar_len = 40
        up_bars = int(prob_up * bar_len)
        down_bars = bar_len - up_bars
        print(f"\n  {target_date} é»„é‡‘ä»·æ ¼é¢„æµ‹:")
        print(f"  ä¸Šæ¶¨æ¦‚ç‡: {prob_up*100:.1f}%  {'â–ˆ' * up_bars}{'â–‘' * down_bars}")
        print(f"  ä¸‹è·Œæ¦‚ç‡: {prob_down*100:.1f}%  {'â–ˆ' * down_bars}{'â–‘' * up_bars}")
        print(f"\n  é¢„æµ‹æ–¹å‘: {'ğŸ“ˆ ä¸Šæ¶¨' if prediction == 'ä¸Šæ¶¨' else 'ğŸ“‰ ä¸‹è·Œ'}")

        # åˆ†é¡¹æ¥æº
        comp = combined_result.get("components", {})
        print(f"\n  æ¦‚ç‡æ„æˆ:")
        print(f"    å›å½’æ¨¡å‹ (æƒé‡{comp.get('regression_weight', 0)*100:.0f}%): ä¸Šæ¶¨æ¦‚ç‡ {comp.get('regression_prob_up', 0)*100:.1f}%")
        print(f"    AIå®šæ€§   (æƒé‡{comp.get('ai_qualitative_weight', 0)*100:.0f}%): ä¸Šæ¶¨æ¦‚ç‡ {comp.get('ai_qualitative_prob_up', 0)*100:.1f}%")

    elif regression_result and "error" not in regression_result:
        # åªæœ‰å›å½’ç»“æœï¼Œæ²¡æœ‰åˆå¹¶ç»“æœ
        print("\n" + "=" * 80)
        print("  â˜… å›å½’æ¨¡å‹é¢„æµ‹ç»“æœ â˜…")
        print("=" * 80)
        prob_up = regression_result.get("probability_up", 0.5)
        prob_down = regression_result.get("probability_down", 0.5)
        bar_len = 40
        up_bars = int(prob_up * bar_len)
        down_bars = bar_len - up_bars
        print(f"\n  {target_date} é»„é‡‘ä»·æ ¼é¢„æµ‹:")
        print(f"  ä¸Šæ¶¨æ¦‚ç‡: {prob_up*100:.1f}%  {'â–ˆ' * up_bars}{'â–‘' * down_bars}")
        print(f"  ä¸‹è·Œæ¦‚ç‡: {prob_down*100:.1f}%  {'â–ˆ' * down_bars}{'â–‘' * up_bars}")

    # å›å½’æ¨¡å‹è¯¦æƒ…
    if regression_result and "error" not in regression_result:
        print("\n" + "-" * 80)
        print("  å›å½’æ¨¡å‹è¯¦æƒ…")
        print("-" * 80)
        mi = regression_result.get("model_info", {})
        print(f"  ç®—æ³•: {mi.get('algorithm', '')}")
        print(f"  è®­ç»ƒæ ·æœ¬: {mi.get('training_samples', '')} ä¸ªäº¤æ˜“æ—¥")
        print(f"  ç‰¹å¾æ•°: {mi.get('features_count', '')}")
        if mi.get("cv_accuracy_mean"):
            print(f"  äº¤å‰éªŒè¯å‡†ç¡®ç‡: {mi['cv_accuracy_mean']*100:.1f}% Â± {mi.get('cv_accuracy_std', 0)*100:.1f}%")
        print(f"  å†å²ä¸Šæ¶¨æ¯”ä¾‹: {mi.get('train_up_ratio', 0)*100:.1f}%")

        top = regression_result.get("top_features", [])[:5]
        if top:
            print(f"\n  æœ€é‡è¦çš„ç‰¹å¾:")
            for tf in top:
                coef = tf.get("coefficient", 0)
                direction = "åˆ©å¤š" if coef > 0 else "åˆ©ç©º"
                print(f"    {tf['feature']}: {direction} (ç³»æ•°={coef:.4f})")

    # AI é¢„æµ‹ä»·æ ¼
    forecast = deep_result.get("forecast", {})
    fp = forecast.get("forecast_price") if forecast else None
    fp = fp or deep_result.get("forecast_price")
    f_low = (forecast.get("forecast_range", {}) or {}).get("low") if forecast else None
    f_low = f_low or deep_result.get("forecast_low")
    f_high = (forecast.get("forecast_range", {}) or {}).get("high") if forecast else None
    f_high = f_high or deep_result.get("forecast_high")
    f_reasoning = forecast.get("reasoning") if forecast else None
    f_reasoning = f_reasoning or deep_result.get("forecast_reasoning")

    if fp:
        print("\n" + "-" * 80)
        print("  AI ä»·æ ¼é¢„æµ‹ï¼ˆå‚è€ƒï¼‰")
        print("-" * 80)
        print(f"  {target_date} é¢„æµ‹ä»·æ ¼: ${fp}")
        if f_low and f_high:
            print(f"  é¢„æµ‹åŒºé—´: ${f_low} ~ ${f_high}")
        if f_reasoning:
            print(f"  é¢„æµ‹ä¾æ®: {f_reasoning}")

    # ä¸»å¯¼å› ç´ 
    dom = deep_result.get("dominant_factors", [])
    if dom:
        print(f"\n  ä¸»å¯¼å› ç´ : {', '.join(dom)}")

    # é£é™©æç¤º
    risks = deep_result.get("risk_notes", [])
    if isinstance(risks, list) and risks:
        print("\n  é£é™©æç¤º:")
        for r in risks:
            print(f"    - {r}")

    print("\n" + "=" * 80)


def run(target_date: str, output_path: str) -> Dict[str, Any]:
    # è·å–çœŸå®å½“å‰æ—¶é—´ï¼ˆç²¾ç¡®åˆ°ç§’ï¼‰
    now = datetime.now()
    current_time = now.strftime("%Y-%m-%d %H:%M:%S")
    current_date = now.strftime("%Y-%m-%d")

    print(f"\nå½“å‰çœŸå®æ—¶é—´: {current_time}")
    print(f"é¢„æµ‹ç›®æ ‡æ—¥æœŸ: {target_date}")

    # è®¡ç®—é¢„æµ‹å¤©æ•°
    try:
        d_target = datetime.strptime(target_date, "%Y-%m-%d")
        forecast_horizon = max(1, (d_target - now.replace(hour=0, minute=0, second=0, microsecond=0)).days)
    except Exception:
        forecast_horizon = 1

    # ===== Step 1: å†å²ä»·æ ¼ï¼ˆè·å–åˆ°æœ€æ–°å¯ç”¨æ•°æ®ï¼‰ =====
    print("\n[1/8] æ­£åœ¨è·å–å†å²é»„é‡‘ä»·æ ¼æ•°æ®ï¼ˆæˆªè‡³å½“å‰æœ€æ–°ï¼‰...")
    df = fetch_gold_prices(end_date=None, lookback_days=365)
    price_summary = get_price_summary(df)
    price_context = format_price_context(price_summary)

    # ===== Step 2: æŠ“å–å®æ—¶æ–°é—» =====
    print("[2/8] æ­£åœ¨æŠ“å–æœ€æ–°é»„é‡‘ç›¸å…³æ–°é—»...")
    news_list = fetch_all_gold_news(max_total=30, period="3d")
    news_context = format_news_context(news_list, max_items=20)
    print(f"  è·å–åˆ° {len(news_list)} æ¡å®æ—¶æ–°é—»")

    # ===== Step 3: AI å› ç´ æ”¶é›† =====
    print("[3/8] æ­£åœ¨è®© AI åŸºäºå®æ—¶æ–°é—»æ”¶é›†å½±å“é‡‘ä»·çš„å…³é”®å› ç´ ...")
    factors_result = collect_factors(
        current_date=current_time, target_date=target_date,
        price_context=price_context, news_context=news_context,
    )
    factors = _extract_factors(factors_result)
    factors_result["factors"] = factors

    # ===== Step 4: AI æ·±åº¦åˆ†æ =====
    print("[4/8] æ­£åœ¨è®© AI åšæ·±åº¦åˆ†æä¸ä»·æ ¼é¢„æµ‹...")
    deep_result = deep_analyze(
        current_date=current_time,
        target_date=target_date,
        price_context=price_context,
        factors_result=factors_result,
        news_context=news_context,
    )

    # ===== Step 5: AI é€‰æ‹©é‡åŒ–ä»£ç†æŒ‡æ ‡ =====
    print("[5/8] æ­£åœ¨è®© AI å°†å› ç´ æ˜ å°„åˆ°é‡åŒ–ä»£ç†æŒ‡æ ‡...")
    proxy_mapping = ai_select_proxies(
        current_date=current_time,
        target_date=target_date,
        factors=factors,
        price_context=price_context,
    )
    selected_proxies = proxy_mapping.get("selected_proxies", [])
    proxy_ids = [sp["proxy_id"] for sp in selected_proxies if sp.get("proxy_id")]
    print(f"  å·²é€‰æ‹© {len(proxy_ids)} ä¸ªé‡åŒ–ä»£ç†æŒ‡æ ‡: {', '.join(proxy_ids)}")

    # ===== Step 6: çˆ¬å–ä»£ç†æŒ‡æ ‡æ—¥åº¦æ•°æ®ï¼ˆæˆªè‡³å½“å‰æœ€æ–°ï¼‰ =====
    print("[6/8] æ­£åœ¨çˆ¬å–ä»£ç†æŒ‡æ ‡çš„æ—¥åº¦æ•°æ®ï¼ˆçº¦1å¹´ï¼Œæˆªè‡³å½“å‰æœ€æ–°ï¼‰...")
    proxy_data = fetch_proxy_data(proxy_ids=proxy_ids, end_date=None, lookback_days=365)
    print(f"  è·å–åˆ° {len(proxy_data)} ä¸ªäº¤æ˜“æ—¥ Ã— {len(proxy_data.columns)} ä¸ªæŒ‡æ ‡çš„æ•°æ®")

    # ===== Step 7: æ—¶é—´åºåˆ—å›å½’ =====
    regression_result = {}
    combined_result = {}
    if not proxy_data.empty and not df.empty:
        print(f"[7/8] æ­£åœ¨æ„å»ºç‰¹å¾çŸ©é˜µå¹¶è®­ç»ƒ Logistic å›å½’æ¨¡å‹ï¼ˆé¢„æµ‹{forecast_horizon}å¤©åæ¶¨è·Œï¼‰...")
        feature_matrix = build_feature_matrix(
            proxy_data=proxy_data,
            gold_prices=df,
            selected_proxies=selected_proxies,
            forecast_horizon=forecast_horizon,
        )
        print(f"  ç‰¹å¾çŸ©é˜µ: {feature_matrix.shape[0]} æ ·æœ¬ Ã— {feature_matrix.shape[1] - 2} ç‰¹å¾")

        regression_result = train_and_predict(
            feature_matrix=feature_matrix,
            selected_proxies=selected_proxies,
            forecast_horizon=forecast_horizon,
        )
        if "error" not in regression_result:
            print(f"  å›å½’æ¨¡å‹ä¸Šæ¶¨æ¦‚ç‡: {regression_result['probability_up']*100:.1f}%")
        else:
            print(f"  [è­¦å‘Š] å›å½’æ¨¡å‹å¤±è´¥: {regression_result.get('error')}")
    else:
        print("[7/8] æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å›å½’åˆ†æ")

    # ===== Step 8: èåˆ AI å®šæ€§ + å›å½’å®šé‡ =====
    print("[8/8] æ­£åœ¨èåˆ AI å®šæ€§åˆ¤æ–­ä¸å›å½’æ¨¡å‹ç»“æœ...")
    ai_bias = deep_result.get("short_term_bias", "neutral")
    ai_conf = deep_result.get("short_term_confidence", "medium")
    if forecast_horizon > 20:
        ai_bias = deep_result.get("mid_term_bias", ai_bias)
        ai_conf = deep_result.get("mid_term_confidence", ai_conf)

    if regression_result and "error" not in regression_result:
        combined_result = compute_combined_probability(
            regression_result=regression_result,
            ai_qualitative_bias=ai_bias,
            ai_confidence=ai_conf,
        )
    else:
        # æ²¡æœ‰å›å½’ç»“æœï¼Œåªç”¨ AI å®šæ€§
        bias_map = {"bullish": 0.65, "bearish": 0.35, "neutral": 0.50}
        prob_up = bias_map.get(ai_bias, 0.5)
        combined_result = {
            "final_probability_up": prob_up,
            "final_probability_down": 1.0 - prob_up,
            "final_prediction": "ä¸Šæ¶¨" if prob_up > 0.5 else "ä¸‹è·Œ",
            "components": {"note": "ä»…åŸºäºAIå®šæ€§åˆ¤æ–­ï¼Œæ— å›å½’æ•°æ®"},
        }

    # ===== é‡åŒ–è¯„åˆ†ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰ =====
    mapping_result = get_level_weight_mapping_from_ai(
        current_date=current_time, target_date=target_date,
        factors=factors, price_context=price_context,
    )
    level_weight_mapping = mapping_result.get("level_weight_mapping")
    score_result = compute_score(factors=factors, level_weight_mapping=level_weight_mapping)
    score_result["ai_level_weight_mapping"] = mapping_result

    # ===== æ‰“å°æŠ¥å‘Š =====
    print_analysis(
        current_time, target_date, price_summary, factors, deep_result, score_result,
        regression_result=regression_result,
        combined_result=combined_result,
        proxy_mapping=proxy_mapping,
    )

    # ===== ä¿å­˜ JSON =====
    report = build_report(
        current_date=current_time,
        target_date=target_date,
        price_summary=price_summary,
        factors_result=factors_result,
        deep_result=deep_result,
        score_result=score_result,
    )
    report["step2_news"] = {"news_count": len(news_list), "news_items": news_list}
    report["step4_proxy_mapping"] = proxy_mapping
    report["step5_regression"] = regression_result
    report["step6_combined_probability"] = combined_result
    save_report_json(report, output_path)
    print(f"\nå®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
    return report


if __name__ == "__main__":
    print("=" * 40)
    print("  AI é»„é‡‘åˆ†æå¸ˆ")
    print("=" * 40)
    now = datetime.now()
    print(f"å½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    target_date = input("è¯·è¾“å…¥é¢„æµ‹ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD): ").strip()
    out = input("è¾“å‡ºæ–‡ä»¶è·¯å¾„ [ç›´æ¥å›è½¦é»˜è®¤ report.json]: ").strip() or "report.json"
    if not os.path.isabs(out):
        out = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), out)
    print(f"\nå¼€å§‹åˆ†æ: {now.strftime('%Y-%m-%d %H:%M:%S')} â†’ {target_date}\n")
    run(target_date=target_date, output_path=out)
